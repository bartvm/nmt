model:
  dim_word_src: 512
  dim_word_trg: 512
  dim: 1024
  encoder: gru
  decoder: gru_cond
  n_words_src: &n_words_src 30000
  n_words: &n_words 30000
  use_dropout: false
data:
  src: /home/vanmerb/data/mt/wmt16.de-en.tok.true.clean.shuf.en
  trg: /home/vanmerb/data/mt/wmt16.de-en.tok.true.clean.shuf.de
  valid_src: /home/vanmerb/data/mt/dev/newstest2013.tok.true.en
  valid_trg: /home/vanmerb/data/mt/dev/newstest2013.tok.true.de
  src_vocab: /home/vanmerb/data/mt/wmt16.de-en.vocab.en
  trg_vocab: /home/vanmerb/data/mt/wmt16.de-en.vocab.de
  n_words_src: *n_words_src
  n_words: *n_words
  batch_size: 64
  valid_batch_size: 64
training: # These affect training
  optimizer: adadelta
  decay_c: 0
  clip_c: 1
  alpha_c: 0
  lrate: 0.0001
  patience: 10
  max_epochs: 5000
  finish_after: 10000000
management: # These don't
  reload_: false
  valid_freq: 5000
  save_freq: 5000
  sample_freq: 1000
  saveto: model
multi:
  valid_sync: false
  train_len: 1
